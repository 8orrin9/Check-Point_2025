import os
import fitz 
import openpyxl
from pptx import Presentation
import docx
from pathlib import Path
from tqdm import tqdm
import requests
from dotenv import load_dotenv
from openai import OpenAI
import tiktoken

load_dotenv()

def SHOULD_SKIP_FILE(file_path):
    ext = file_path.suffix.lower()
    try:
        if ext == ".pdf":
            doc = fitz.open(str(file_path))
            if len(doc) >= 10:
                print(f"[SKIP] PDF 페이지 수가 10 이상: {file_path.name}")
                return True
        elif ext == ".pptx":
            prs = Presentation(str(file_path))
            if len(prs.slides) >= 10:
                print(f"[SKIP] PPTX 슬라이드 수가 10 이상: {file_path.name}")
                return True
        elif ext == ".docx":
            doc = docx.Document(str(file_path))
            if len(doc.paragraphs) >= 50:
                print(f"[SKIP] DOCX 문단 수가 많음 (50 이상): {file_path.name}")
                return True
        elif ext == ".xlsx":
            wb = openpyxl.load_workbook(str(file_path), read_only=True)
            if len(wb.sheetnames) >= 3:
                print(f"[SKIP] 시트 수가 3 이상: {file_path.name}")
                return True
        return False
    except Exception as e:
        print(f"[ERROR] 파일 확인 실패: {file_path.name} - {e}")
        return True

def COUNT_TOKENS(text: str, model="gpt-4o"):
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

def TRIM_TEXT_TO_TOKEN_LIMIT(text, max_tokens=4000, model="gpt-4o"):
    encoding = tiktoken.encoding_for_model(model)
    tokens = encoding.encode(text)
    return encoding.decode(tokens[:max_tokens])

def CALL_UPSTAGE_OCR(file_path):
    try:
        api_key = os.getenv("UPSTAGE_API_KEY")
        url = "https://api.upstage.ai/v1/document-digitization"
        headers = {"Authorization": f"Bearer {api_key}"}
        with open(file_path, "rb") as file:
            files = {"document": file}
            data = {"model": "ocr"}
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get("text", "")
    except Exception as e:
        print(f"[ERROR] OCR 실패: {file_path} - {e}")
        return ""

def CALL_UPSTAGE_PARSER(file_path):
    try:
        api_key = os.getenv("UPSTAGE_API_KEY")
        url = "https://api.upstage.ai/v1/document-digitization"
        headers = {"Authorization": f"Bearer {api_key}"}
        with open(file_path, "rb") as file:
            files = {"document": file}
            data = {"base64_encoding": "['figure']", "model": "document-parse"}
            response = requests.post(url, headers=headers, files=files, data=data)
            if response.status_code != 200:
                print(f"[DEBUG] Response code: {response.status_code}, Message: {response.text}")
            response.raise_for_status()
            return response.json().get("text", "")
    except Exception as e:
        print(f"[ERROR] 파싱 실패: {file_path} - {e}")
        return ""

def CALL_SOLAR_FOR_MERGE(ocr_text, parsed_text):
    try:
        api_key = os.getenv("UPSTAGE_API_KEY")
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.upstage.ai/v1"
        )
        system_prompt = (
            "당신은 문서 구조를 정돈하는 전문가입니다. 두 문서 OCR 및 파싱 결과를 통합하여 사람이 읽기 좋은 하나의 문서로 만드세요.\n"
            "통합에 기준이 되는 것은 OCR, 파싱 결과입니다. OCR 결과는 모든 텍스트가 포함되어 있지만 레이아웃 정보가 없습니다. 파싱 결과는 레이아웃과 표 구조를 포함하지만 텍스트가 누락되어 있을 수 있습니다. 아래 내용에 따라 파싱 결과를 보충하여 반환하세요:\n"
            "- OCR 텍스트를 기반으로 파싱 결과에서 누락된 내용을 보완하세요.\n"
            "- 파싱 결과의 표 구조 등 레이아웃 정보를 최대한 보존하세요.\n"
            "- 파싱 결과에 표가 포함되어 있다면, 표 안의 텍스트는 OCR 결과로 보완하세요.\n"
            "- OCR 텍스트는 절대 누락되면 안 됩니다.\n"
            "- 설명, 해석, 안내 문구는 포함하지 마세요."
        )
        user_prompt = (
            f"[OCR 결과]\n{ocr_text}\n\n"
            f"[파싱 결과]\n{parsed_text}\n\n"
            f"[통합된 문서 출력]"
        )
        stream = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=False
        )
        return stream.choices[0].message.content
    except Exception as e:
        print(f"[ERROR] SOLAR 통합 실패: {e}")
        return ""

# def PROCESS_DOCUMENTS(file_paths):
#     if isinstance(file_paths, Path):
#         file_paths = [file_paths]
#     texts = []
#     for file_path in tqdm(file_paths, desc="Processing Documents"):
#         ext = file_path.suffix.lower()
#         if ext == ".txt":
#             try:
#                 with open(file_path, "r", encoding="utf-8") as f:
#                     texts.append(f.read())
#             except Exception as e:
#                 print(f"[ERROR] TXT 파일 처리 실패: {file_path.name} - {e}")
#         else:
#             ocr_text = CALL_UPSTAGE_OCR(file_path)
#             parsed_text = CALL_UPSTAGE_PARSER(file_path)
#             token_count = COUNT_TOKENS(ocr_text + parsed_text)

#             if token_count <= 4000: # 영어 4자 / 한글 1자에 1~1.5 토큰
#                 merged = CALL_SOLAR_FOR_MERGE(ocr_text, parsed_text)
#             else:
#                 print(f"[NOTICE] 토큰 수 초과 → 앞부분만 병합 처리: {file_path.name}")
#                 ocr_trimmed = TRIM_TEXT_TO_TOKEN_LIMIT(ocr_text, 2000)
#                 parsed_trimmed = TRIM_TEXT_TO_TOKEN_LIMIT(parsed_text, 2000)
#                 merged = CALL_SOLAR_FOR_MERGE(ocr_trimmed, parsed_trimmed)
#             texts.append(merged)
#     return "\n\n".join(texts)

def PROCESS_DOCUMENTS(file_paths):
    if isinstance(file_paths, Path):
        file_paths = [file_paths]

    texts = []
    for file_path in tqdm(file_paths, desc="Processing Documents"):
        if SHOULD_SKIP_FILE(file_path):
            continue

        ext = file_path.suffix.lower()
        if ext == ".txt":
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    texts.append(f.read())
            except Exception as e:
                print(f"[ERROR] TXT 파일 처리 실패: {file_path.name} - {e}")
        else:
            try:
                ocr_text = CALL_UPSTAGE_OCR(file_path)
                parsed_text = CALL_UPSTAGE_PARSER(file_path)
                total_tokens = COUNT_TOKENS(ocr_text) + COUNT_TOKENS(parsed_text)

                if total_tokens >= 8000:
                    print(f"[NOTICE] 토큰 수 초과 → 앞부분만 병합 처리: {file_path.name}")
                    ocr_trimmed = TRIM_TEXT_TO_TOKEN_LIMIT(ocr_text, 4000)
                    parsed_trimmed = TRIM_TEXT_TO_TOKEN_LIMIT(parsed_text, 4000)
                    merged = CALL_SOLAR_FOR_MERGE(ocr_trimmed, parsed_trimmed)
                else:
                    merged = CALL_SOLAR_FOR_MERGE(ocr_text, parsed_text)

                texts.append(merged)
            except Exception as e:
                print(f"[ERROR] 문서 처리 실패: {file_path.name} - {e}")
                texts.append("")

    return "\n\n".join(texts)
